{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "## Those are the libraries that we will use to create our model and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 785\n"
     ]
    }
   ],
   "source": [
    "##First, we will import the dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "#Must convert pandas dataframe to numpy array for matrix algebra.\n",
    "\n",
    "data = data.to_numpy()\n",
    "m,n = data.shape\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 785)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now that we have the data, we will split it into the training and testing data.\n",
    "np.random.shuffle(data)\n",
    "train_data = data[:int(0.95*m),:]\n",
    "test_data = data[int(0.95*m):,:]\n",
    "# Using 95% of the data in training and 5% in testing. skewed split towards training since this is a well known dataset.\n",
    "\n",
    "test_data.shape\n",
    "# Gives us 2100 samples to test performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 39900) (39900,)\n",
      "(784, 2100) (2100,)\n"
     ]
    }
   ],
   "source": [
    "#Now we will split the data into the input and output.\n",
    "X_train = train_data[:,1:].T\n",
    "Y_train = train_data[:,0].T\n",
    "X_test = test_data[:,1:].T\n",
    "Y_test = test_data[:,0].T\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 39900)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One hot encoding the output.\n",
    "from tkinter.tix import Y_REGION\n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "    Y = Y.astype(int)\n",
    "    Y_one_hot = np.zeros((Y.shape[0],10))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y_one_hot[i,Y[i]] = 1\n",
    "    return Y_one_hot.T\n",
    "one_hot(Y_train).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model architecture\n",
    "##  Input layer: 784 neurons (28x28 pixels) (784 inputs)\n",
    "##  Hidden layer: 100 neurons (ReLU activation)\n",
    "##  Output layer: 10 neurons (0-9) (Softmax activation) \n",
    "\n",
    "\n",
    "\n",
    "# Implementation:\n",
    "#  step 1: Initialize weights and biases\n",
    "#  step 2: Forward propagation\n",
    "#  step 3: Backpropagation\n",
    "#  step 4: Update weights and biases\n",
    " \n",
    " \n",
    "def init_params():   # step 1  \n",
    "    W1 = np.random.rand(10,784)\n",
    "    b1 = np.zeros((10,1))\n",
    "    W2 = np.random.rand(10,10)\n",
    "    b2 = np.zeros((10,1))\n",
    "    return W1,b1,W2,b2\n",
    "\n",
    "def forward_prop(X_train, W1, b1, W2, b2): #step 2\n",
    "    Z1 = np.dot(W1,X_train) + b1\n",
    "    A1 = np.maximum(0,Z1) #ReLU activation: if Z1 is positive, else 0.\n",
    "    Z2 = np.dot(W2,A1) + b2\n",
    "    A2 = np.exp(Z2)/np.sum(np.exp(Z2),axis=0) #Softmax activation: derived from the softmax formuula (e^Z2/sum(e^Z2))\n",
    "    return Z1,A1, Z2, A2\n",
    "\n",
    "def backprop(X_train, Y_train, Z1,Z2,A1,A2, W2): #step 3\n",
    "    one_hot_y = one_hot(Y_train)\n",
    "    dZ2 = A2 - one_hot_y\n",
    "    dW2 = 1/Y_train.size * np.dot(dZ2,A1.T)\n",
    "    db2 = 1/Y_train.size * np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1 = np.dot(W2.T,dZ2) * (A1 > 0) #ReLU derivative: if A1 is positive, else 0.\n",
    "    dW1 = 1/Y_train.size * np.dot(dZ1,X_train.T)\n",
    "    db1 = 1/Y_train.size * np.sum(dZ1,axis=1,keepdims=True)\n",
    "    return dW1,db1,dW2,db2\n",
    "\n",
    "def update_params(W1,b1,W2,b2,dW1,db1,dW2,db2,alpha): #step 4\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1,b1,W2,b2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #now implementing gradient descent.\n",
    "def gradient_descent(X_train, Y_train, alpha, iter):\n",
    "    W1,b1,W2,b2 = init_params()\n",
    "    for i in range(iter):\n",
    "      Z1,A1,Z2,A2 = forward_prop(X_train,W1,b1,W2,b2)\n",
    "      dW1,db1,dW2,db2 = backprop(X_train, Y_train, Z1, Z2, A1, A2, W2)\n",
    "      W1,b1,W2,b2 = update_params(W1,b1,W2,b2,dW1,db1,dW2,db2,alpha)\n",
    "      ## Output logging to help debug and see the training progress.  \n",
    "      if i % 5 == 0:\n",
    "        print(\"Iteration: \",i) # prints iteration number every 10 iterations.\n",
    "        print('prediction: ', np.argmax(A2,0).sum()) # prints prediction every 10 iterations.\n",
    "    return W1,b1,W2,b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_14084\\1471412647.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  A2 = np.exp(Z2)/np.sum(np.exp(Z2),axis=0) #Softmax activation: derived from the softmax formuula (e^Z2/sum(e^Z2))\n",
      "C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_14084\\1471412647.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "  A2 = np.exp(Z2)/np.sum(np.exp(Z2),axis=0) #Softmax activation: derived from the softmax formuula (e^Z2/sum(e^Z2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "prediction:  0\n",
      "Iteration:  5\n",
      "prediction:  0\n",
      "Iteration:  10\n",
      "prediction:  0\n",
      "Iteration:  15\n",
      "prediction:  0\n",
      "Iteration:  20\n",
      "prediction:  0\n",
      "Iteration:  25\n",
      "prediction:  0\n",
      "Iteration:  30\n",
      "prediction:  0\n",
      "Iteration:  35\n",
      "prediction:  0\n",
      "Iteration:  40\n",
      "prediction:  0\n",
      "Iteration:  45\n",
      "prediction:  0\n",
      "Iteration:  50\n",
      "prediction:  0\n",
      "Iteration:  55\n",
      "prediction:  0\n",
      "Iteration:  60\n",
      "prediction:  0\n",
      "Iteration:  65\n",
      "prediction:  0\n",
      "Iteration:  70\n",
      "prediction:  0\n",
      "Iteration:  75\n",
      "prediction:  0\n",
      "Iteration:  80\n",
      "prediction:  0\n",
      "Iteration:  85\n",
      "prediction:  0\n",
      "Iteration:  90\n",
      "prediction:  0\n",
      "Iteration:  95\n",
      "prediction:  0\n",
      "Iteration:  100\n",
      "prediction:  0\n",
      "Iteration:  105\n",
      "prediction:  0\n",
      "Iteration:  110\n",
      "prediction:  0\n",
      "Iteration:  115\n",
      "prediction:  0\n",
      "Iteration:  120\n",
      "prediction:  0\n",
      "Iteration:  125\n",
      "prediction:  0\n",
      "Iteration:  130\n",
      "prediction:  0\n",
      "Iteration:  135\n",
      "prediction:  0\n",
      "Iteration:  140\n",
      "prediction:  0\n",
      "Iteration:  145\n",
      "prediction:  0\n",
      "Iteration:  150\n",
      "prediction:  0\n",
      "Iteration:  155\n",
      "prediction:  0\n",
      "Iteration:  160\n",
      "prediction:  0\n",
      "Iteration:  165\n",
      "prediction:  0\n",
      "Iteration:  170\n",
      "prediction:  0\n",
      "Iteration:  175\n",
      "prediction:  0\n",
      "Iteration:  180\n",
      "prediction:  0\n",
      "Iteration:  185\n",
      "prediction:  0\n",
      "Iteration:  190\n",
      "prediction:  0\n",
      "Iteration:  195\n",
      "prediction:  0\n"
     ]
    }
   ],
   "source": [
    "W1,b1, W2,b2 = gradient_descent(X_train, Y_train, .1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]] [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]] [[nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan]] [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "print (W1,b1,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93aa56aaf092cc48edb18a400e2b8d907b19181ab850d8edad30d48dcd99f0f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
